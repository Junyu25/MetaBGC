#!/usr/bin/env python

#####################################################################################
#@author: francinecamacho
# This file is a component of MetaBGC (Metagenomic identifier of Biosynthetic Gene Clusters)
# (contact Francine Camacho at camachofrancine@gmail.com).
#####################################################################################
from Utils.Utils import RunHMMDirectory
import ntpath
import re
import ExtractFASTASeq from ExtractFASTASeq
from rpy2.robjects.vectors import StrVector
import os
import pandas as pd
import glob
import rpy2.robjects.packages as rpackages
import rpy2.robjects as robjects
from rpy2.robjects import pandas2ri

pandas2ri.activate()

#Filter HMM results using predetermined spHMM models score cutoffs 
def filter_spHMM_data(spHMM_df, cutoff_df):
	filter_spHMM_df = pd.DataFrame()
	for index, row in cutoff_df.iterrows():
		cyclase_model = cutoff_df.at[index,'cyclase_type']
		model_interval = cutoff_df.at[index,'interval']
		cutoff = cutoff_df.at[index,'cutoff']
		#filter spHMM dataframe with designated cutoffs 
		filter_df = spHMM_df.query("HMMScore >= @cutoff & cyclaseType == @cyclase_model & interval == @model_interval").reset_index(drop=True)
		filter_spHMM_df = filter_spHMM_df.append(filter_df)
	return(filter_spHMM_df)

#reformat IDs and filter duplicate readIDs and keep the highest HMM Score 
def create_reformat_data(input_df, outdir):
	os.chdir(outdir)
	base = rpackages.importr('base')
	packageNames = ('tidyverse')
	utils = rpackages.importr('utils')
	utils.chooseCRANmirror(ind=1)
	packnames_to_install = [x for x in packageNames if not rpackages.isinstalled(x)]
	if len(packnames_to_install) > 0:
		utils.install_packages(StrVector(packnames_to_install))
	tidyverse = rpackages.importr('tidyverse')
	robjects.r['options'](warn=-1)
	reformat_df = robjects.r('''
		function(hmmdf) {
			hmmdfRecoded <- separate(hmmdf, readID, into = c("read","F_R_read_frame"), sep = "_", extra = "merge") %>%
			select(-c(F_R_read_frame))
			hmmdfRecodedDFUnique<-aggregate(HMMScore ~ read + Sample + sampleType + cyclaseType , hmmdfRecoded, max)
			colnames(hmmdfRecodedDFUnique)<-c("readID","Sample", "sampleType", "cyclaseType","HMMScore")
			write_tsv(hmmdfRecodedDFUnique, "spHMM-filtered-results.txt", col_names = T)
		}
		''')
	input_r_df = pandas2ri.py2ri(input_df) # convert pandas df to R datafame

	data_filter = reformat_df(input_r_df)
	return(data_filter)

def parse_sample_reads(reformat_df, reads_outdir):
	os.chdir(reads_outdir)
	parseReads = robjects.r('''
		function(HMMdf) {
			samples<-unique(HMMdf$Sample)
			for (s in 1:length(samples)){
				currentSample<-samples[s]
				currentSampleResults<- HMMdf %>% filter(Sample == currentSample)
				currentSampleReads<- unique(currentSampleResults$readID)
				fileName<-paste0(currentSample,paste("-","detected-reads",sep =""), ".txt", sep ="")
				write.table(currentSampleReads,fileName, quote = F, row.names = F, col.names = F )
		}}
		''')
	parseReads(reformat_df)

def main(hmm_file, outdir, cutoff_file, fasta_dir):
	spHMM_df = pd.read_csv(hmm_file, sep ="\t", names = ["readID", "sampleType", "Sample", "cyclaseType", "HMMScore", "window","interval"])
	cutoff_df = pd.read_csv(cutoff_file, sep ="\t", header=0)
	spHMM_df_filtered = filter_spHMM_data(spHMM_df, cutoff_df)
	spHMM_df_filtered_reformat = create_reformat_data(spHMM_df_filtered, outdir)
	parse_sample_reads(spHMM_df_filtered_reformat, fasta_dir)

if __name__ == '__main__':
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument('--sphmm_directory', required=True, help= "High performance spHMM directory generated by MetaBGC-Build.")
	parser.add_argument('--nucl_seq_directory', required=True, help="Directory with nuleotide fasta files.")
	parser.add_argument('--prot_seq_directory', required=True, help="Directory with protein translated fasta files.")
	parser.add_argument('--prot_family_name', required=True, help="Name of the protein family.")
	parser.add_argument('--cohort_name', required=True, help="Name of the sample/cohort name.")
	parser.add_argument('--output_directory', required=True, help="Directory to save results.")
	parser.add_argument('--cpu', required=False, help="Number of threads. Def.: 4")

	args = parser.parse_args()

	if args.cpu is not None:
		CPU_THREADS = args.cpu

	# HMMER search
	hmm_search_directory = os.path.join(args.output_directory, 'hmm_identify_search')
	os.makedirs(hmm_search_directory, 0o777, True)
	for filename in os.listdir(args.hmm_directory):
		fileBase = ntpath.basename(filename)
		hmmInterval = fileBase.split("__")[2]
		if filename.endswith(".hmm"):
			RunHMMDirectory(args.prot_seq_directory, filename, args.cohort_name, args.prot_family_name, "30_10", hmmInterval,
						hmm_search_directory, CPU_THREADS)

	allHMMResult = hmm_search_directory + os.sep + "CombinedHmmSearch.txt"
	with open(allHMMResult, 'w') as outfile:
		for subdir, dirs, files in os.walk(hmm_search_directory):
			for file in files:
				filePath = os.path.join(subdir, file)
				if re.match(r".*txt$", file) and os.path.getsize(filePath) > 0:
					with open(filePath) as infile:
						for line in infile:
							outfile.write(line)

	identify_directory = os.path.join(args.output_directory, 'identify_result')
	os.makedirs(identify_directory, 0o777, True)
	fasta_dir = os.path.join(args.output_directory, 'fasta_result')
	os.makedirs(identify_directory, 0o777, True)
	cutoff_file = os.path.join(args.hmm_directory, "F1_Cutoff.txt")
	main(allHMMResult, identify_directory, cutoff_file, fasta_dir)

	allHMMResult = fasta_dir + os.sep + "CombinedReadIds.txt"
	with open(allHMMResult, 'w') as outfile:
		for filename in os.listdir(fasta_dir):
			if filename.endswith(".txt"):
				with open(filename) as infile:
					for line in infile:
						outfile.write(line)

	multiFastaFile = args.output_directory + os.sep + "CombinedFASTASeqs.fasta"
	ExtractFASTASeq(args.nucl_seq_directory,multiFastaFile,allHMMResult)

